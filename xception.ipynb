{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xception.ipynb","provenance":[{"file_id":"1Ntv7UckB6v0X_QWf4Q-gtHDLrJfqGFzF","timestamp":1589584285805},{"file_id":"1-bLaIRd3YUzA4FGmlVAH9x7ajL7sqSdF","timestamp":1589579564189},{"file_id":"1-6DASEUPcnjRkjSpBQGuS0AmAJqejjy8","timestamp":1588945271913},{"file_id":"1gDOODICIEL0pEFquIN84V9c0Coe4O-h0","timestamp":1588945208963},{"file_id":"1m9w66XRcgA_b2KI1MDAXLlBc5MdOV4GM","timestamp":1588809412546}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"dmCQQjvUIJpE","colab_type":"code","colab":{}},"source":["!pip install PyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1CCMf-kNQUHm","colab_type":"code","colab":{}},"source":["import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","download = drive.CreateFile({'id': '1YDTb0DduoP_kQwmEm3d5CEQk3wDyPhfe'})\n","download.GetContentFile('FER 2013.zip')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awWOxPhp8rR6","colab_type":"code","colab":{}},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7mk9mbd7oVO","colab_type":"code","colab":{}},"source":["import os\n","import zipfile\n","\n","local_zip = '/content/FER 2013.zip'\n","\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","\n","zip_ref.extractall('/content')\n","zip_ref.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsQGsWam4qLP","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import matplotlib.pyplot as plt\n","\n","base_dir=\"/content/FER 2013/\"\n","\n","img_size = 299\n","plt.figure(0, figsize=(12,20))\n","ctr = 0\n","\n","for expression in os.listdir(base_dir+\"train/\"):\n","    for i in range(1,6):\n","        ctr += 1\n","        plt.subplot(7,5,ctr)\n","        img = load_img(base_dir+\"train/\" + expression + \"/\" +os.listdir(base_dir+\"train/\"+ expression)[i], target_size=(img_size, img_size))\n","        plt.imshow(img)\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_6npOuq4vG4","colab_type":"code","colab":{}},"source":["for expression in os.listdir(base_dir+\"train/\"):\n","    print(str(len(os.listdir(base_dir+\"train/\" + expression))) + \" \" + expression + \" images\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFRbR7qt4yuy","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","%matplotlib inline\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n","from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.utils import plot_model\n","\n","from IPython.display import SVG, Image\n","#from livelossplot.tf_keras import PlotLossesCallback\n","import tensorflow as tf\n","print(\"Tensorflow version:\", tf.__version__)\n","img_size = 299\n","batch_size = 32\n","\n","\n","\n","\n","datagen_train = ImageDataGenerator(rescale = 1.0/255., \n","\n","     featurewise_center=False,  # set input mean to 0 over the dataset\n","    samplewise_center=False,  # set each sample mean to 0\n","    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","    samplewise_std_normalization=False,  # divide each input by its std\n","    zca_whitening=False,  # apply ZCA whitening\n","    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","    width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n","    height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n","    horizontal_flip=True,  # randomly flip images\n","    vertical_flip=False,   # randomly flip images\n","    zoom_range=0.2\n","  )\n","\n","train_generator = datagen_train.flow_from_directory(base_dir+\"train/\",\n","                                                    target_size=(img_size,img_size),\n","                                                    batch_size=batch_size,\n","                                                    class_mode='categorical'\n","                                                    \n","                                                    )\n","\n","datagen_validation  = ImageDataGenerator( rescale = 1.0/255.\n","                                         \n","    \n","   \n","  )\n","validation_generator = datagen_validation.flow_from_directory(base_dir+\"test/\",\n","                                                    target_size=(img_size,img_size),\n","                                                    batch_size=batch_size,\n","                                                    class_mode='categorical',\n","                                                    shuffle=False\n","                                                             )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oX4FVU344hzE","colab_type":"code","colab":{}},"source":["import os\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","\n","  \n","from tensorflow.keras.applications.xception import Xception\n","\n","img_width=299\n","img_height=299\n","pre_trained_model = Xception(input_shape=(img_width,img_height, 3), weights='imagenet', include_top=False)\n","\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","  \n","pre_trained_model.summary()\n","\n","\n","\n","#last_layer = pre_trained_model.get_layer('mixed7')\n","#print('last layer output shape: ', last_layer.output_shape)\n","#last_output = last_layer.output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"euAdbRwm4uE4","colab_type":"code","colab":{}},"source":["%%time\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \n","\n","from tensorflow.keras.regularizers import l2\n","\n","\n","x = layers.Flatten()(pre_trained_model.output)\n","x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001),\n","           bias_regularizer=l2(0.001))(x)\n","x=layers.BatchNormalization()(x)\n","x = layers.Dropout(0.3)(x)                  \n","\n","x = layers.Dense(512, activation='relu',kernel_regularizer=l2(0.001),\n","           bias_regularizer=l2(0.001))(x)\n","x=layers.BatchNormalization()(x)\n","x = layers.Dropout(0.3)(x) \n","\n","x = layers.Dense (7, activation='softmax')(x)            \n","\n","model = Model( pre_trained_model.input, x)\n","\n","input_shape=(299,299,3)\n","model.build(input_shape)\n","\n","#model.build(input_shape) \n","# Définition de l'optimizer (avec quelques paramètres qu'il faudra adapter à ses besoins)\n","#opt = RAdam(lr=0.1,total_steps=10000, warmup_proportion=0.1, min_lr=1e-6)\n","opt = Adam(lr=0.0005)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","epochs = 30\n","steps_per_epoch = train_generator.n//train_generator.batch_size\n","validation_steps = validation_generator.n//validation_generator.batch_size\n","\n","\n","\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n","                             patience=2, min_lr=0.0000001, mode='auto')\n","callbacks = [reduce_lr]\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=epochs,\n","    validation_data = validation_generator,\n","    validation_steps = validation_steps,\n","   callbacks=callbacks\n",")\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJORpjubCg0C","colab_type":"code","colab":{}},"source":["\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc      = history.history[     'accuracy' ]\n","val_acc  = history.history[ 'val_accuracy' ]\n","loss     = history.history[    'loss' ]\n","val_loss = history.history['val_loss' ]\n","\n","epochs   = range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     acc )\n","plt.plot  ( epochs, val_acc )\n","plt.title ('Training and validation accuracy')\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     loss )\n","plt.plot  ( epochs, val_loss )\n","plt.title ('Training and validation loss'   )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSnVJcDXy_m_","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","num_of_test_samples=7178\n","emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n","num_classes = len(emotion_labels)\n","Y_pred = model.predict_generator(validation_generator, num_of_test_samples // batch_size+1)\n","y_pred = np.argmax(Y_pred, axis=1)\n","print('Confusion Matrix')\n","cm=confusion_matrix(validation_generator.classes, y_pred)\n","print(cm)\n","cm_normalised = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","sns.set(font_scale=1.5) \n","fig, ax = plt.subplots(figsize=(10,10))\n","ax = sns.heatmap(cm_normalised, annot=True, linewidths=0, square=True, \n","                    cmap=\"Greens\", yticklabels=emotion_labels, xticklabels=emotion_labels, vmin=0, vmax=np.max(cm_normalised), \n","                    fmt=\".2f\", annot_kws={\"size\": 20})\n","ax.set(xlabel='Predicted label', ylabel='True label')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NOqPYd4XH6uz","colab_type":"text"},"source":["fine-tuning\n"]},{"cell_type":"code","metadata":{"id":"2D1RdOAiHZ6t","colab_type":"code","colab":{}},"source":["# reset our data generators\n","train_generator.reset()\n","validation_generator.reset()\n","# now that the head FC layers have been trained/initialized, lets\n","# unfreeze the final set of CONV layers and make them trainable\n","for layer in pre_trained_model.layers[115:]:\n","\tlayer.trainable = True\n","# loop over the layers in the model and show which ones are trainable\n","# or not\n","for layer in pre_trained_model.layers:\n","\tprint(\"{}: {}\".format(layer, layer.trainable))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAqNNHUsHimP","colab_type":"code","colab":{}},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","opt = Adam(lr=0.0005)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","epochs = 9\n","# 20 epochs et meme 15 suffira\n","steps_per_epoch = train_generator.n//train_generator.batch_size\n","validation_steps = validation_generator.n//validation_generator.batch_size\n","\n","\n","checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n","                             save_weights_only=True, mode='max', verbose=1, save_best_only=True)\n","\n","\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n","                             patience=2, min_lr=0.0000001, mode='auto')\n","callbacks = [reduce_lr,checkpoint]\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=epochs,\n","    validation_data = validation_generator,\n","    validation_steps = validation_steps,\n","   callbacks=callbacks\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5BN8DyHHoPP","colab_type":"code","colab":{}},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rO25KZlmyQtE","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(\"model_weights.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIlM-KcNyUgN","colab_type":"code","colab":{}},"source":["model_json = model.to_json()\n","with open(\"model.json\", \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmYWCMeDyYdU","colab_type":"code","colab":{}},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RQoUmtUHuFA","colab_type":"code","colab":{}},"source":["files.download(\"model.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvyHFoH2xXkR","colab_type":"code","colab":{}},"source":["#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc      = history.history[     'accuracy' ]\n","val_acc  = history.history[ 'val_accuracy' ]\n","loss     = history.history[    'loss' ]\n","val_loss = history.history['val_loss' ]\n","\n","epochs   = range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     acc )\n","plt.plot  ( epochs, val_acc )\n","plt.title ('Training and validation accuracy')\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot  ( epochs,     loss )\n","plt.plot  ( epochs, val_loss )\n","plt.title ('Training and validation loss'   )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5DSMOW9_zNM","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","num_of_test_samples=7178\n","emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n","num_classes = len(emotion_labels)\n","Y_pred = model.predict_generator(validation_generator, num_of_test_samples // batch_size+1)\n","y_pred = np.argmax(Y_pred, axis=1)\n","print('Confusion Matrix')\n","cm=confusion_matrix(validation_generator.classes, y_pred)\n","print(cm)\n","cm_normalised = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","sns.set(font_scale=1.5) \n","fig, ax = plt.subplots(figsize=(10,10))\n","ax = sns.heatmap(cm_normalised, annot=True, linewidths=0, square=True, \n","                    cmap=\"Greens\", yticklabels=emotion_labels, xticklabels=emotion_labels, vmin=0, vmax=np.max(cm_normalised), \n","                    fmt=\".2f\", annot_kws={\"size\": 20})\n","ax.set(xlabel='Predicted label', ylabel='True label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQwI0ifwxh66","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report\n","\n","test_steps=validation_generator.n//validation_generator.batch_size+1\n","\n","print(\"[INFO] evaluating after fine-tuning network ...\")\n","validation_generator.reset()\n","predIdxs = model.predict_generator(validation_generator,\n","\tsteps=test_steps)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print(classification_report(validation_generator.classes, predIdxs,\n","\ttarget_names=validation_generator.class_indices.keys(), zero_division=1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QizChE3vbpBN","colab_type":"code","colab":{}},"source":["import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = fn\n","  img = image.load_img(path, target_size=(299, 299))\n","  yy = image.img_to_array(img)\n","  yy = np.expand_dims(yy, axis=0)\n","\n","  images = np.vstack([yy])\n","  classes = model.predict(images, batch_size=10)\n","  print(fn)\n","\n","  print(np.argmax(classes[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-Wx9jpL2xN_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}